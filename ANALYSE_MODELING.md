# ğŸ“Š Analyse du Notebook `02_modeling.ipynb`

## âœ… Points Positifs

### 1. **Structure et Organisation**
- âœ… Code bien organisÃ© avec sections claires
- âœ… Utilisation de modules personnalisÃ©s (`preprocessing.py`, `modeling.py`)
- âœ… Commentaires personnels qui rendent le code authentique
- âœ… Pipeline de preprocessing rÃ©utilisable

### 2. **Gestion du DÃ©sÃ©quilibre**
- âœ… Utilisation de SMOTE pour Ã©quilibrer les classes
- âœ… Split stratifiÃ© pour prÃ©server la distribution dans train/test
- âœ… Sauvegarde du scaler pour la production

### 3. **Comparaison de ModÃ¨les**
- âœ… Comparaison systÃ©matique entre Logistic Regression et Random Forest
- âœ… MÃ©triques complÃ¨tes (Accuracy, Precision, Recall, F1, ROC-AUC)
- âœ… Visualisations d'Ã©valuation intÃ©grÃ©es

---

## âš ï¸ ProblÃ¨mes Critiques IdentifiÃ©s

### 1. **Random Forest ne dÃ©tecte AUCUNE fraude** ğŸ”´

**ProblÃ¨me observÃ© :**
```
Random Forest:
- TP = 0, FN = 10 (ne dÃ©tecte AUCUNE fraude !)
- Precision = 0.0000
- Recall = 0.0000
- F1-Score = 0.0000
```

**Causes probables :**
- `class_weight='balanced'` peut Ãªtre insuffisant avec un dataset si petit
- Le Random Forest est trop conservateur aprÃ¨s SMOTE
- Pas d'optimisation des hyperparamÃ¨tres (max_depth, min_samples_split, etc.)
- Le seuil de dÃ©cision par dÃ©faut (0.5) n'est pas adaptÃ©

**Solutions :**
```python
# Option 1 : Ajuster les hyperparamÃ¨tres
RandomForestClassifier(
    n_estimators=200,  # Plus d'arbres
    max_depth=15,      # Plus profond
    min_samples_split=2,  # Plus flexible
    min_samples_leaf=1,
    class_weight={0: 1, 1: 10},  # Poids personnalisÃ© plus agressif
    random_state=42
)

# Option 2 : Optimiser le seuil de dÃ©cision
from sklearn.metrics import precision_recall_curve
y_pred_proba = model.predict_proba(X_test)[:, 1]
precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)
# Trouver le seuil optimal (ex: F1-score max)
f1_scores = 2 * (precision * recall) / (precision + recall)
optimal_threshold = thresholds[np.argmax(f1_scores)]
```

### 2. **Logistic Regression : Performance trÃ¨s faible** ğŸŸ¡

**ProblÃ¨me observÃ© :**
```
Logistic Regression:
- F1-Score = 0.0072 (trÃ¨s faible)
- Precision = 0.0037
- Recall = 0.2000
```

**Causes :**
- Avec seulement 10 fraudes dans le test set, les mÃ©triques sont instables
- Le modÃ¨le prÃ©dit trop de faux positifs (FP=542)
- Pas d'optimisation du seuil de dÃ©cision

**Solutions :**
- Utiliser une validation croisÃ©e stratifiÃ©e pour avoir plus de donnÃ©es de test
- Optimiser le seuil de dÃ©cision avec Precision-Recall curve
- Essayer d'autres algorithmes (XGBoost, LightGBM) qui gÃ¨rent mieux le dÃ©sÃ©quilibre

### 3. **Dataset trop petit pour Ã©valuation fiable** ğŸŸ¡

**ProblÃ¨me :**
- 10 000 transactions totales
- Seulement 50 fraudes (0.5%)
- Test set : seulement 10 fraudes

**Impact :**
- Les mÃ©triques sont trÃ¨s instables
- Un seul faux nÃ©gatif change drastiquement le Recall
- Difficile de gÃ©nÃ©raliser les rÃ©sultats

**Solutions :**
```python
# Utiliser une validation croisÃ©e stratifiÃ©e
from sklearn.model_selection import StratifiedKFold

skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
cv_scores = []

for train_idx, val_idx in skf.split(X, y):
    X_train_cv, X_val_cv = X[train_idx], X[val_idx]
    y_train_cv, y_val_cv = y[train_idx], y[val_idx]
    # ... entraÃ®nement et Ã©valuation
```

### 4. **Pas d'optimisation des hyperparamÃ¨tres** ğŸŸ¡

**ProblÃ¨me :**
- HyperparamÃ¨tres par dÃ©faut ou basiques
- Pas de GridSearch ou RandomSearch
- Pas de tuning du seuil de dÃ©cision

**Solution :**
```python
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer, f1_score

# Scorer personnalisÃ© (F1-score)
f1_scorer = make_scorer(f1_score)

# GridSearch pour Random Forest
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 15, 20, None],
    'min_samples_split': [2, 5, 10],
    'class_weight': ['balanced', {0: 1, 1: 5}, {0: 1, 1: 10}]
}

grid_search = GridSearchCV(
    RandomForestClassifier(random_state=42),
    param_grid,
    cv=StratifiedKFold(n_splits=5),
    scoring=f1_scorer,
    n_jobs=-1
)
```

### 5. **Pas d'analyse des features importantes** ğŸŸ¡

**Manque :**
- Feature importance pour comprendre ce qui influence le modÃ¨le
- Visualisation des features les plus importantes
- Potentielle feature selection

**Solution :**
```python
# AprÃ¨s entraÃ®nement du Random Forest
feature_importance = pd.DataFrame({
    'feature': feature_names,
    'importance': best_detector.model.feature_importances_
}).sort_values('importance', ascending=False)

# Visualisation
plt.figure(figsize=(10, 8))
sns.barplot(data=feature_importance.head(15), x='importance', y='feature')
plt.title('Top 15 Features les plus importantes')
plt.show()
```

### 6. **Ã‰valuation incomplÃ¨te** ğŸŸ¡

**Manque :**
- Pas de courbe Precision-Recall (plus importante que ROC pour dÃ©sÃ©quilibre)
- Pas d'analyse des coÃ»ts (coÃ»t d'un faux nÃ©gatif vs faux positif)
- Pas de mÃ©triques par classe dÃ©taillÃ©es

**Solution :**
```python
# Courbe Precision-Recall (plus informative que ROC pour dÃ©sÃ©quilibre)
from sklearn.metrics import precision_recall_curve, average_precision_score

precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)
ap_score = average_precision_score(y_test, y_pred_proba)

plt.plot(recall, precision, label=f'AP = {ap_score:.3f}')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend()
plt.show()
```

---

## ğŸ”§ Recommandations d'AmÃ©lioration

### PrioritÃ© 1 : Corriger le Random Forest

1. **Ajuster les hyperparamÃ¨tres manuellement :**
```python
RandomForestClassifier(
    n_estimators=200,
    max_depth=15,
    min_samples_split=2,
    min_samples_leaf=1,
    class_weight={0: 1, 1: 20},  # Poids plus agressif
    random_state=42,
    n_jobs=-1
)
```

2. **Optimiser le seuil de dÃ©cision :**
```python
# Trouver le seuil optimal pour maximiser F1-score
y_pred_proba = model.predict_proba(X_test)[:, 1]
f1_scores = []
thresholds = np.arange(0.1, 0.9, 0.01)

for threshold in thresholds:
    y_pred_thresh = (y_pred_proba >= threshold).astype(int)
    f1 = f1_score(y_test, y_pred_thresh)
    f1_scores.append(f1)

optimal_threshold = thresholds[np.argmax(f1_scores)]
print(f"Seuil optimal : {optimal_threshold:.3f}")
```

### PrioritÃ© 2 : AmÃ©liorer l'Ã©valuation

1. **Utiliser une validation croisÃ©e :**
```python
from sklearn.model_selection import cross_val_score, StratifiedKFold

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
cv_scores = cross_val_score(
    model, X_train, y_train,
    cv=cv,
    scoring='f1',
    n_jobs=-1
)
print(f"F1-Score CV: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")
```

2. **Ajouter des mÃ©triques business :**
```python
# CoÃ»t d'un faux nÃ©gatif (fraude non dÃ©tectÃ©e) vs faux positif
cost_fn = 100  # CoÃ»t d'une fraude non dÃ©tectÃ©e
cost_fp = 1    # CoÃ»t d'une transaction bloquÃ©e Ã  tort

total_cost = (fn * cost_fn) + (fp * cost_fp)
print(f"CoÃ»t total : {total_cost}")
```

### PrioritÃ© 3 : Essayer d'autres algorithmes

1. **XGBoost avec scale_pos_weight :**
```python
import xgboost as xgb

# Calculer le ratio de dÃ©sÃ©quilibre
scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()

model = xgb.XGBClassifier(
    n_estimators=200,
    max_depth=6,
    learning_rate=0.1,
    scale_pos_weight=scale_pos_weight,
    random_state=42
)
```

2. **LightGBM :**
```python
import lightgbm as lgb

model = lgb.LGBMClassifier(
    n_estimators=200,
    max_depth=6,
    learning_rate=0.1,
    is_unbalance=True,  # GÃ¨re automatiquement le dÃ©sÃ©quilibre
    random_state=42
)
```

### PrioritÃ© 4 : AmÃ©liorer le preprocessing

1. **Feature Engineering :**
```python
# CrÃ©er des features dÃ©rivÃ©es
df['Amount_log'] = np.log1p(df['Amount'])
df['Time_hour'] = df['Time'] % (24 * 3600) / 3600
df['V_sum'] = df[['V1', 'V2', 'V3']].sum(axis=1)
```

2. **Feature Selection :**
```python
from sklearn.feature_selection import SelectKBest, f_classif

# SÃ©lectionner les K meilleures features
selector = SelectKBest(f_classif, k=20)
X_selected = selector.fit_transform(X_train, y_train)
```

---

## ğŸ“ Code d'AmÃ©lioration SuggÃ©rÃ©

Voici un exemple de code amÃ©liorÃ© pour la section de modÃ©lisation :

```python
# 1. Optimisation du seuil de dÃ©cision
def find_optimal_threshold(y_true, y_pred_proba):
    """Trouve le seuil optimal pour maximiser F1-score"""
    precision, recall, thresholds = precision_recall_curve(y_true, y_pred_proba)
    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)
    optimal_idx = np.argmax(f1_scores)
    return thresholds[optimal_idx], f1_scores[optimal_idx]

# 2. Random Forest amÃ©liorÃ©
rf_improved = RandomForestClassifier(
    n_estimators=200,
    max_depth=15,
    min_samples_split=2,
    min_samples_leaf=1,
    class_weight={0: 1, 1: 20},  # Poids plus agressif
    random_state=42,
    n_jobs=-1
)

rf_improved.fit(X_train, y_train)
y_pred_proba_rf = rf_improved.predict_proba(X_test)[:, 1]

# Trouver le seuil optimal
optimal_threshold, optimal_f1 = find_optimal_threshold(y_test, y_pred_proba_rf)
y_pred_rf_optimized = (y_pred_proba_rf >= optimal_threshold).astype(int)

print(f"Seuil optimal : {optimal_threshold:.3f}")
print(f"F1-Score avec seuil optimal : {f1_score(y_test, y_pred_rf_optimized):.4f}")

# 3. Validation croisÃ©e
from sklearn.model_selection import cross_validate

cv_results = cross_validate(
    rf_improved, X_train, y_train,
    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
    scoring=['f1', 'precision', 'recall', 'roc_auc'],
    return_train_score=True
)

print(f"\nğŸ“Š RÃ©sultats CV :")
print(f"F1-Score : {cv_results['test_f1'].mean():.4f} (+/- {cv_results['test_f1'].std() * 2:.4f})")
print(f"Precision : {cv_results['test_precision'].mean():.4f}")
print(f"Recall : {cv_results['test_recall'].mean():.4f}")
```

---

## ğŸ¯ RÃ©sumÃ© des Actions Prioritaires

1. âœ… **Corriger Random Forest** : Ajuster hyperparamÃ¨tres et seuil de dÃ©cision
2. âœ… **Validation croisÃ©e** : Pour avoir des mÃ©triques plus fiables
3. âœ… **Optimisation du seuil** : Ne pas utiliser 0.5 par dÃ©faut
4. âœ… **Essayer XGBoost/LightGBM** : Meilleure gestion du dÃ©sÃ©quilibre
5. âœ… **Feature importance** : Comprendre ce qui influence le modÃ¨le
6. âœ… **MÃ©triques business** : CoÃ»ts des erreurs

---

## ğŸ’¡ Note Finale

Le code est bien structurÃ© et professionnel, mais les performances actuelles sont insuffisantes pour un systÃ¨me de production. Les principales amÃ©liorations Ã  apporter concernent :

1. **L'optimisation des hyperparamÃ¨tres** (surtout pour Random Forest)
2. **L'optimisation du seuil de dÃ©cision** (crucial pour le dÃ©sÃ©quilibre)
3. **L'utilisation de validation croisÃ©e** (pour des mÃ©triques plus fiables)
4. **L'essai d'autres algorithmes** (XGBoost, LightGBM)

Avec ces amÃ©liorations, vous devriez obtenir des rÃ©sultats beaucoup plus satisfaisants ! ğŸš€

