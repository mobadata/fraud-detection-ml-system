"""
Dashboard Streamlit pour la d√©tection de fraude

Interface interactive pour tester le mod√®le de d√©tection de fraude
"""

import streamlit as st
import pandas as pd
import numpy as np
import joblib
from pathlib import Path
import sys
import plotly.graph_objects as go
import plotly.express as px

# Ajouter le dossier src au path
sys.path.append(str(Path(__file__).parent.parent / "src"))

from explainability import FraudExplainer
from lime.lime_tabular import LimeTabularExplainer

# Configuration de la page
st.set_page_config(
    page_title="D√©tection de Fraude - Dashboard",
    page_icon="üîê",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Styles CSS personnalis√©s
st.markdown("""
    <style>
    .big-font {
        font-size:30px !important;
        font-weight: bold;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        margin: 10px 0;
    }
    </style>
    """, unsafe_allow_html=True)

# Chemins des mod√®les
MODEL_PATH = Path(__file__).parent.parent / "models" / "best_model_logistic.pkl"
SCALER_PATH = Path(__file__).parent.parent / "models" / "scaler.pkl"
DATA_PATH = Path(__file__).parent.parent / "data" / "raw" / "creditcard.csv"


@st.cache_resource
def load_model_and_scaler():
    """Charge le mod√®le, le scaler et l'explainer SHAP (avec cache)"""
    try:
        if MODEL_PATH.exists() and SCALER_PATH.exists():
            model = joblib.load(MODEL_PATH)
            scaler = joblib.load(SCALER_PATH)
            
            # Charger un √©chantillon de donn√©es pour SHAP
            explainer = None
            if DATA_PATH.exists():
                df_sample = pd.read_csv(DATA_PATH).sample(n=min(200, len(pd.read_csv(DATA_PATH))), random_state=42)
                X_sample = df_sample.drop('Class', axis=1)
                X_sample_scaled = scaler.transform(X_sample)
                explainer = FraudExplainer(model, X_sample_scaled)
            
            return model, scaler, explainer, None
        else:
            error = f"Mod√®le ou scaler non trouv√©. Veuillez entra√Æner le mod√®le d'abord."
            return None, None, None, error
    except Exception as e:
        return None, None, None, f"Erreur : {str(e)}"


@st.cache_data
def load_data():
    """Charge les donn√©es (avec cache)"""
    try:
        if DATA_PATH.exists():
            df = pd.read_csv(DATA_PATH)
            return df, None
        else:
            return None, "Dataset non trouv√©"
    except Exception as e:
        return None, f"Erreur : {str(e)}"


def predict_fraud(model, scaler, features):
    """
    Pr√©dit si une transaction est frauduleuse
    
    Args:
        model: Mod√®le de ML
        scaler: Scaler pour normaliser
        features: Array de features (30 valeurs)
        
    Returns:
        prediction, probability
    """
    features_scaled = scaler.transform(features.reshape(1, -1))
    prediction = model.predict(features_scaled)[0]
    probability = model.predict_proba(features_scaled)[0][1]
    return prediction, probability


# Titre principal
st.title("üîê Syst√®me de D√©tection de Fraude")
st.markdown("---")

# Chargement du mod√®le et des donn√©es
model, scaler, explainer, model_error = load_model_and_scaler()
df, data_error = load_data()

# Sidebar
with st.sidebar:
    st.header("‚öôÔ∏è Configuration")
    
    # Statut du syst√®me
    st.subheader("üìä Statut du syst√®me")
    if model is not None and scaler is not None:
        st.success("‚úÖ Mod√®le charg√©")
        st.success("‚úÖ Scaler charg√©")
    else:
        st.error(f"‚ùå {model_error}")
    
    if df is not None:
        st.success(f"‚úÖ Dataset charg√© ({len(df):,} transactions)")
    else:
        st.warning(f"‚ö†Ô∏è {data_error}")
    
    st.markdown("---")
    
    # Mode de test
    st.subheader("üéÆ Mode")
    mode = st.radio(
        "Choisissez un mode",
        ["üé≤ Test avec donn√©es r√©elles", "‚úèÔ∏è Saisie manuelle", "üìä Analyse dataset"]
    )

# Onglets principaux
if mode == "üé≤ Test avec donn√©es r√©elles":
    st.header("üé≤ Test avec donn√©es r√©elles")
    st.markdown("S√©lectionnez une transaction du dataset pour tester le mod√®le")
    
    if df is not None and model is not None:
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # Filtrer par type de transaction
            trans_type = st.selectbox(
                "Type de transaction",
                ["Toutes", "Normales uniquement", "Fraudes uniquement"]
            )
            
            if trans_type == "Normales uniquement":
                df_filtered = df[df['Class'] == 0]
            elif trans_type == "Fraudes uniquement":
                df_filtered = df[df['Class'] == 1]
            else:
                df_filtered = df
            
            # S√©lection d'une transaction
            if len(df_filtered) > 0:
                idx = st.slider("Index de la transaction", 0, len(df_filtered)-1, 0)
                transaction = df_filtered.iloc[idx]
                
                # Afficher les infos
                st.subheader("üìã D√©tails de la transaction")
                col_a, col_b, col_c = st.columns(3)
                with col_a:
                    st.metric("Montant", f"{transaction['Amount']:.2f} ‚Ç¨")
                with col_b:
                    st.metric("Temps", f"{transaction['Time']:.0f} s")
                with col_c:
                    actual_label = "Fraude" if transaction['Class'] == 1 else "Normale"
                    st.metric("Vraie classe", actual_label)
                
                # Bouton de pr√©diction
                if st.button("üîç Analyser cette transaction", key="predict_btn"):
                    # Extraire les features
                    feature_cols = [col for col in df.columns if col != 'Class']
                    features = transaction[feature_cols].values  # Garder 1D pour predict_fraud
                    
                    # Pr√©diction
                    pred, proba = predict_fraud(model, scaler, features)
                    
                    # Affichage des r√©sultats
                    st.markdown("---")
                    st.subheader("üéØ R√©sultats de l'analyse")
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        if pred == 1:
                            st.error("üö® **FRAUDE D√âTECT√âE**")
                        else:
                            st.success("‚úÖ **Transaction Normale**")
                    
                    with col2:
                        st.metric("Probabilit√© de fraude", f"{proba*100:.2f}%")
                    
                    with col3:
                        # V√©rification
                        is_correct = (pred == transaction['Class'])
                        if is_correct:
                            st.success("‚úÖ Pr√©diction correcte")
                        else:
                            st.error("‚ùå Pr√©diction incorrecte")
                    
                    # Gauge de probabilit√©
                    fig = go.Figure(go.Indicator(
                        mode="gauge+number",
                        value=proba*100,
                        title={'text': "Risque de fraude (%)"},
                        gauge={
                            'axis': {'range': [0, 100]},
                            'bar': {'color': "darkred" if proba > 0.5 else "green"},
                            'steps': [
                                {'range': [0, 30], 'color': "lightgreen"},
                                {'range': [30, 70], 'color': "yellow"},
                                {'range': [70, 100], 'color': "lightcoral"}
                            ],
                            'threshold': {
                                'line': {'color': "red", 'width': 4},
                                'thickness': 0.75,
                                'value': 50
                            }
                        }
                    ))
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Recommandation
                    st.subheader("üí° Recommandation")
                    if proba > 0.9:
                        st.error("üö® **Bloquer imm√©diatement** - Risque tr√®s √©lev√©")
                    elif proba > 0.7:
                        st.warning("‚ö†Ô∏è **V√©rification suppl√©mentaire requise** - Risque √©lev√©")
                    elif proba > 0.5:
                        st.info("‚ö° **Surveillance accrue** - Risque mod√©r√©")
                    else:
                        st.success("‚úÖ **Autoriser la transaction** - Risque faible")
                    
                    # Explicabilit√© avec LIME
                    st.markdown("---")
                    st.subheader("üîç Explicabilit√© LIME - Pourquoi cette pr√©diction ?")
                    st.markdown("**LIME** (Local Interpretable Model-agnostic Explanations) explique cette pr√©diction sp√©cifique")
                    
                    with st.spinner("Calcul des explications LIME..."):
                        try:
                            # Cr√©er l'explainer LIME
                            lime_explainer = LimeTabularExplainer(
                                training_data=np.zeros((10, len(feature_cols))),  # Dummy data
                                feature_names=feature_cols,
                                class_names=['Normal', 'Fraude'],
                                mode='classification'
                            )
                            
                            # Expliquer la pr√©diction
                            exp = lime_explainer.explain_instance(
                                data_row=features.flatten(),
                                predict_fn=lambda x: model.predict_proba(scaler.transform(x)),
                                num_features=10
                            )
                            
                            # Extraire les features importantes
                            lime_list = exp.as_list()
                            lime_df = pd.DataFrame(lime_list, columns=['Feature', 'Impact'])
                            lime_df = lime_df.sort_values('Impact', key=abs, ascending=False)
                            
                            # Afficher le tableau
                            st.markdown("**Top 10 Features influentes selon LIME**")
                            st.dataframe(lime_df, use_container_width=True)
                            
                            # Graphique
                            fig = go.Figure(go.Bar(
                                x=lime_df['Impact'],
                                y=lime_df['Feature'],
                                orientation='h',
                                marker=dict(
                                    color=['red' if x > 0 else 'blue' for x in lime_df['Impact']],
                                )
                            ))
                            fig.update_layout(
                                title="Impact des features sur la pr√©diction",
                                xaxis_title="Impact (+ = vers Fraude, - = vers Normal)",
                                yaxis_title="Feature",
                                height=400
                            )
                            st.plotly_chart(fig, use_container_width=True)
                            
                            st.info("üìä **Comment lire** :\n"
                                   "- üî¥ **Barres rouges (positives)** : Poussent vers la FRAUDE\n"
                                   "- üîµ **Barres bleues (n√©gatives)** : Poussent vers NORMAL\n"
                                   "- Plus la barre est longue, plus l'influence est forte")
                            
                        except Exception as e:
                            st.warning(f"‚ö†Ô∏è Explications LIME non disponibles : {str(e)}")
            else:
                st.warning("Aucune transaction disponible avec ce filtre")
        
        with col2:
            # Statistiques du dataset
            st.subheader("üìä Statistiques")
            total = len(df)
            frauds = df['Class'].sum()
            normal = total - frauds
            fraud_rate = (frauds / total) * 100
            
            st.metric("Total transactions", f"{total:,}")
            st.metric("Transactions normales", f"{normal:,}")
            st.metric("Fraudes", f"{frauds:,}")
            st.metric("Taux de fraude", f"{fraud_rate:.3f}%")
    else:
        st.error("Mod√®le ou donn√©es non disponibles")

elif mode == "‚úèÔ∏è Saisie manuelle":
    st.header("‚úèÔ∏è Saisie manuelle d'une transaction")
    st.markdown("Entrez les valeurs des features pour tester une transaction personnalis√©e")
    
    if model is not None:
        st.warning("‚ö†Ô∏è Les features V1-V28 sont des composantes PCA anonymis√©es. Valeurs typiques : entre -5 et 5")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Features principales")
            time_val = st.number_input("Time (secondes)", value=0.0, step=1.0)
            amount_val = st.number_input("Amount (‚Ç¨)", value=100.0, min_value=0.0, step=1.0)
        
        with col2:
            st.subheader("G√©n√©ration al√©atoire")
            if st.button("üé≤ G√©n√©rer des valeurs al√©atoires"):
                st.session_state['random_values'] = np.random.randn(28) * 2  # Features V1-V28
        
        st.subheader("Features V1-V28")
        st.info("üí° Conseil : Utilisez le bouton 'G√©n√©rer des valeurs al√©atoires' pour avoir des valeurs r√©alistes")
        
        # Cr√©er un expander pour les features V
        with st.expander("üîß Configurer les features V1-V28", expanded=False):
            v_features = []
            cols = st.columns(4)
            for i in range(28):
                col_idx = i % 4
                with cols[col_idx]:
                    default_val = st.session_state.get('random_values', np.zeros(28))[i]
                    v_val = st.number_input(f"V{i+1}", value=float(default_val), step=0.1, format="%.2f")
                    v_features.append(v_val)
        
        # Bouton de pr√©diction
        if st.button("üîç Analyser cette transaction", key="predict_manual"):
            # Cr√©er le vecteur de features
            features = np.array(v_features + [time_val, amount_val])
            
            # Pr√©diction
            pred, proba = predict_fraud(model, scaler, features)
            
            # Affichage
            st.markdown("---")
            st.subheader("üéØ R√©sultats")
            
            col1, col2 = st.columns(2)
            with col1:
                if pred == 1:
                    st.error("üö® **FRAUDE D√âTECT√âE**")
                else:
                    st.success("‚úÖ **Transaction Normale**")
            
            with col2:
                st.metric("Probabilit√© de fraude", f"{proba*100:.2f}%")
            
            # Gauge
            fig = go.Figure(go.Indicator(
                mode="gauge+number",
                value=proba*100,
                title={'text': "Risque de fraude (%)"},
                gauge={
                    'axis': {'range': [0, 100]},
                    'bar': {'color': "darkred" if proba > 0.5 else "green"},
                    'steps': [
                        {'range': [0, 30], 'color': "lightgreen"},
                        {'range': [30, 70], 'color': "yellow"},
                        {'range': [70, 100], 'color': "lightcoral"}
                    ]
                }
            ))
            st.plotly_chart(fig, use_container_width=True)
            
            # Explicabilit√© avec LIME
            st.markdown("---")
            st.subheader("üîç Explicabilit√© LIME - Pourquoi cette pr√©diction ?")
            
            with st.spinner("Calcul des explications LIME..."):
                try:
                    feature_names = [f'V{i}' for i in range(1, 29)] + ['Time', 'Amount']
                    
                    # Cr√©er l'explainer LIME
                    lime_explainer = LimeTabularExplainer(
                        training_data=np.zeros((10, 30)),
                        feature_names=feature_names,
                        class_names=['Normal', 'Fraude'],
                        mode='classification'
                    )
                    
                    # Expliquer la pr√©diction
                    exp = lime_explainer.explain_instance(
                        data_row=features.flatten(),
                        predict_fn=lambda x: model.predict_proba(scaler.transform(x)),
                        num_features=10
                    )
                    
                    # Extraire les features importantes
                    lime_list = exp.as_list()
                    lime_df = pd.DataFrame(lime_list, columns=['Feature', 'Impact'])
                    lime_df = lime_df.sort_values('Impact', key=abs, ascending=False)
                    
                    # Afficher
                    st.markdown("**Top 10 Features influentes**")
                    st.dataframe(lime_df, use_container_width=True)
                    
                    # Graphique
                    fig = go.Figure(go.Bar(
                        x=lime_df['Impact'],
                        y=lime_df['Feature'],
                        orientation='h',
                        marker=dict(color=['red' if x > 0 else 'blue' for x in lime_df['Impact']])
                    ))
                    fig.update_layout(
                        title="Impact des features",
                        xaxis_title="Impact (+ = Fraude, - = Normal)",
                        height=400
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                    st.info("üìä üî¥ Rouge = Fraude | üîµ Bleu = Normal")
                    
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Explications LIME non disponibles : {str(e)}")
    else:
        st.error("Mod√®le non disponible")

elif mode == "üìä Analyse dataset":
    st.header("üìä Analyse du dataset")
    
    if df is not None:
        tab1, tab2, tab3 = st.tabs(["üìà Vue d'ensemble", "üí∞ Analyse montants", "‚è±Ô∏è Analyse temporelle"])
        
        with tab1:
            st.subheader("Vue d'ensemble du dataset")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Total transactions", f"{len(df):,}")
            with col2:
                frauds = df['Class'].sum()
                st.metric("Fraudes", f"{frauds:,}")
            with col3:
                fraud_rate = (frauds / len(df)) * 100
                st.metric("Taux de fraude", f"{fraud_rate:.3f}%")
            with col4:
                avg_amount = df['Amount'].mean()
                st.metric("Montant moyen", f"{avg_amount:.2f} ‚Ç¨")
            
            # Distribution des classes
            st.subheader("Distribution des classes")
            class_counts = df['Class'].value_counts()
            fig = px.pie(
                values=class_counts.values,
                names=['Normal', 'Fraude'],
                title="R√©partition Normal vs Fraude",
                color_discrete_sequence=['green', 'red']
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with tab2:
            st.subheader("Analyse des montants")
            
            # Stats
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**Transactions normales**")
                normal_amounts = df[df['Class'] == 0]['Amount']
                st.write(normal_amounts.describe())
            with col2:
                st.markdown("**Fraudes**")
                fraud_amounts = df[df['Class'] == 1]['Amount']
                st.write(fraud_amounts.describe())
            
            # Histogrammes
            fig = go.Figure()
            fig.add_trace(go.Histogram(
                x=df[df['Class'] == 0]['Amount'],
                name='Normal',
                opacity=0.7,
                marker_color='green'
            ))
            fig.add_trace(go.Histogram(
                x=df[df['Class'] == 1]['Amount'],
                name='Fraude',
                opacity=0.7,
                marker_color='red'
            ))
            fig.update_layout(
                title="Distribution des montants par classe",
                xaxis_title="Montant (‚Ç¨)",
                yaxis_title="Fr√©quence",
                barmode='overlay'
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with tab3:
            st.subheader("Analyse temporelle")
            
            df_temp = df.copy()
            df_temp['Time_hours'] = df_temp['Time'] / 3600
            
            # Distribution temporelle
            fig = go.Figure()
            fig.add_trace(go.Histogram(
                x=df_temp[df_temp['Class'] == 0]['Time_hours'],
                name='Normal',
                opacity=0.7,
                marker_color='green',
                nbinsx=50
            ))
            fig.add_trace(go.Histogram(
                x=df_temp[df_temp['Class'] == 1]['Time_hours'],
                name='Fraude',
                opacity=0.7,
                marker_color='red',
                nbinsx=50
            ))
            fig.update_layout(
                title="Distribution temporelle des transactions",
                xaxis_title="Temps (heures)",
                yaxis_title="Nombre de transactions",
                barmode='overlay'
            )
            st.plotly_chart(fig, use_container_width=True)
    else:
        st.error("Dataset non disponible")

# Footer
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: gray;'>
        <p>üîê Syst√®me de D√©tection de Fraude | Version 1.0.0</p>
        <p>D√©velopp√© avec ‚ù§Ô∏è par Moussa Ba</p>
    </div>
    """,
    unsafe_allow_html=True
)

